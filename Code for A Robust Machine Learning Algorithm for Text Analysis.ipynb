{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import re\n",
    "import timeit\n",
    "import os\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_raw_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    This function generates raw text data from FOMC transcripts\n",
    "    \n",
    "    returns a list where each element is the full text within each FOMC meeting\n",
    "    \n",
    "    It will take about 4-5 minutes\n",
    "    \"\"\"\n",
    "\n",
    "    cwd = os.getcwd() # get current working directory\n",
    "    base_directory = './FOMC_pdf' # set directory of pdfs\n",
    "    raw_doc = os.listdir(base_directory) # as above\n",
    "    filelist = sorted(raw_doc) # sort the pdfs in order\n",
    "    onlyfiles = [f for f in raw_doc if os.path.isfile(os.path.join(base_directory, f))] # keep if in correct dir\n",
    "    date = [f[4:10] for f in onlyfiles] # keep the dates in pdfs\n",
    "\n",
    "    raw_text = pd.DataFrame(columns = ['Date','Speaker', 'content']) #empty dataframe\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    for i,file in enumerate(filelist):\n",
    "        print('Document {} of {}'.format(i, len(filelist)))\n",
    "        \n",
    "        parsed = parser.from_file(os.path.join(cwd, 'FOMC_pdf',file)) # parse the pdf\n",
    "        interjections = re.split('\\nMR. |\\nMS. |\\nCHAIRMAN |\\nVICE CHAIRMAN ', parsed['content']) # split the entire string by the names (looking for MR, MS, Chairman or Vice Chairman)\n",
    "        temp_df = pd.DataFrame(columns = ['Date','Speaker','content']) # create a temporary dataframe\n",
    "        interjections = [interjection.replace('\\n',' ') for interjection in interjections] # replace \\n linebreaks with spaces\n",
    "        temp = [re.split('(^\\S*)', interjection.lstrip()) for interjection in interjections] # changed to this split because sometimes (rarely) there was not a period, either other punctuation or whitespace\n",
    "        \n",
    "        speaker = []\n",
    "        content = []\n",
    "        for interjection in temp:\n",
    "            speaker.append(interjection[1].strip(string.punctuation))\n",
    "            content.append(interjection[2])\n",
    "            \n",
    "        temp_df['Speaker'] = speaker\n",
    "\n",
    "        temp_df['content'] = content # save interjections\n",
    "\n",
    "        temp_df['Date'] = date[i]\n",
    "        raw_text = pd.concat([raw_text, temp_df], ignore_index = True)\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    raw_text.index = raw_text['Date'] # set dataframe index to the Date\n",
    "    raw_text.to_excel('raw_text.xlsx') # save as raw_text.xlsx\n",
    "\n",
    "    print(\"Documents processed. Time: {}\".format(end - start))\n",
    "    \n",
    "    return raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import topicmodels\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    main function for preprocessing\n",
    "        \n",
    "    This function writes the tokenized documents, which includes columns of \n",
    "    \n",
    "    Date: date of the meeting\n",
    "    Section: FOMC1 or FOMC2\n",
    "    Speaker: speaker of the interjection\n",
    "    content: list of tokens in the interjection\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    text = pd.read_excel('raw_text.xlsx')\n",
    "    \n",
    "    text_separated = separation(text)\n",
    "    \n",
    "    text_separated_col = find_collocation(text_separated)\n",
    "    text_separated_col['content'] = tokenize(text_separated_col['content'].values)\n",
    "    text_separated_col.to_excel('FOMC_token_separated_col.xlsx')\n",
    "    \n",
    "def tokenize(content):\n",
    "    '''\n",
    "    Code for tokenization:\n",
    "        1. remove words with length of 1\n",
    "        2. remove non-alphabetical words\n",
    "        3. remove stop words\n",
    "        4. stem all words\n",
    "    '''\n",
    "    FOMC_token = []\n",
    "    for statement in content:\n",
    "        statement = statement.lower()\n",
    "        docsobj = topicmodels.RawDocs([statement], \"long\")\n",
    "        docsobj.token_clean(1)\n",
    "        docsobj.stopword_remove(\"tokens\")\n",
    "        docsobj.stem()\n",
    "        docsobj.stopword_remove(\"stems\")\n",
    "        ps = PorterStemmer()\n",
    "        FOMC_token.append(' '.join([ps.stem(word) for word in docsobj.tokens[0]]))\n",
    "        \n",
    "    return FOMC_token\n",
    "\n",
    "def separation(raw_text):\n",
    "    \n",
    "    separation_rule = pd.read_excel('Separation.xlsx')\n",
    "    \n",
    "    FOMC_separation = pd.DataFrame(columns = ['Date','Speaker','content','Section'])\n",
    "    for i in separation_rule.index:\n",
    "\n",
    "        temp1 = raw_text[raw_text[\"Date\"] == i].iloc[separation_rule['FOMC1_start'][i]:separation_rule['FOMC1_end'][i]]\n",
    "        temp1['Section'] = 1\n",
    "        if separation_rule['FOMC2_end'][i] == 'end':\n",
    "            temp2 = raw_text[raw_text[\"Date\"] == i].iloc[separation_rule['FOMC2_start'][i]:]\n",
    "        else:\n",
    "            temp2 = raw_text[raw_text[\"Date\"] == i].iloc[separation_rule['FOMC2_start'][i]:separation_rule['FOMC2_end'][i]]\n",
    "        temp2['Section'] = 2\n",
    "        FOMC_separation = FOMC_separation.append(temp1, ignore_index=True)\n",
    "        FOMC_separation = FOMC_separation.append(temp2, ignore_index = True)\n",
    "        \n",
    "    FOMC_separation.to_excel('raw_text_separated.xlsx')\n",
    "    return FOMC_separation\n",
    "\n",
    "def find_collocation(raw_text_separated):\n",
    "    \n",
    "    content = raw_text_separated['content'].apply(lambda x: re.sub(r'[^\\w\\s]','',x)) #remove punctuations\n",
    "    \n",
    "    big_document = content.apply(lambda x: x.split(' ')).values\n",
    "    \n",
    "    bigram_list = bigrams(big_document)\n",
    "    trigram_list = trigram(big_document)\n",
    "    \n",
    "    replace_word = [''.join(x.split(' ')) + 'xx' for x in bigram_list] + [''.join(x.split(' ')) + 'xxx' for x in trigram_list]\n",
    "    \n",
    "    dict_collocation = dict(zip(bigram_list + trigram_list, replace_word))\n",
    "\n",
    "    content = content.apply(lambda x: replace_collocation(x, dict_collocation))\n",
    "    \n",
    "    raw_text_separated['content'] = content\n",
    "    raw_text_separated.to_excel('FOMC_separated_Collocation.xlsx')\n",
    "    return raw_text_separated\n",
    "\n",
    "def bigrams(big_document):\n",
    "    \n",
    "    ignored_words = nltk.corpus.stopwords.words('english')\n",
    "    ignored_words.append('percent')\n",
    "    ignored_words.append('governor')\n",
    "    ignored_words.append('dont')\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "    finder = BigramCollocationFinder.from_documents(big_document)\n",
    "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "    finder.apply_freq_filter(150)\n",
    "    \n",
    "    return [' '.join(x) for x in list(finder.ngram_fd.keys())]\n",
    "\n",
    "\n",
    "def trigram(big_document):\n",
    "    \n",
    "    ignored_words = nltk.corpus.stopwords.words('english')\n",
    "    ignored_words.append('percent')\n",
    "    ignored_words.append('governor')\n",
    "    ignored_words.append('dont')\n",
    "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "    finder = TrigramCollocationFinder.from_documents(big_document)\n",
    "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "    finder.apply_freq_filter(100)\n",
    "    \n",
    "    return [' '.join(x) for x in list(finder.ngram_fd.keys())]\n",
    "\n",
    "def replace_collocation(string, dict_collocation):\n",
    "    \n",
    "    for key in dict_collocation.keys():\n",
    "        \n",
    "        string = string.replace(key, dict_collocation[key])\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_term_document(option = None):\n",
    "    '''\n",
    "    option = 'text' or 'matrix' for return options\n",
    "    \n",
    "    '''\n",
    "    data = pd.read_excel('FOMC_token_separated_col.xlsx')\n",
    "    texts = []\n",
    "    for line in data['content'].fillna(' ').values:\n",
    "        texts.append(line.split(' '))\n",
    "        \n",
    "    dictionary2 = corpora.Dictionary(texts)\n",
    "    corpus2 = [dictionary2.doc2bow(text) for text in texts]\n",
    "    \n",
    "    term_document2 = gensim.matutils.corpus2dense(corpus2, num_terms=len(dictionary2.keys()))\n",
    "    \n",
    "    TF = 1+np.log(term_document2.sum(axis = 1))\n",
    "    IDF = np.log(term_document2.shape[1] / np.count_nonzero(term_document2, axis = 1))\n",
    "\n",
    "    TF_IDF = pd.Series(dict(zip(dictionary2.keys(), TF*IDF)))\n",
    "    \n",
    "    # use top 9000 in TF-IDF\n",
    "    keys_to_use2 = TF_IDF.sort_values(ascending = False)[:9000].index.values\n",
    "    \n",
    "    TF_IDF.sort_values(ascending = False).reset_index()[0].plot()\n",
    "    plt.show()\n",
    "    \n",
    "    dictionary2.filter_tokens(good_ids = keys_to_use2)\n",
    "    \n",
    "    #pd.Series(dictionary2.token2id).to_csv('dictionary.csv')\n",
    "    \n",
    "    new_text = []\n",
    "    for line in texts:\n",
    "        new_text.append([x for x in line if x in dictionary2.token2id.keys()])\n",
    "    \n",
    "    new_corpus2 = [dictionary2.doc2bow(text) for text in texts]\n",
    "    new_term_document2 = gensim.matutils.corpus2dense(new_corpus2, num_terms=len(dictionary2.keys()))\n",
    "    \n",
    "    #pd.DataFrame(new_term_document2).to_csv('Matrix_interjection_tfidf.csv')\n",
    "    \n",
    "    if option == 'text':\n",
    "        return new_text\n",
    "    elif option == 'matrix':\n",
    "        return new_term_document2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAwp3EVEYkjhLiISQwp3EZEY+v9o4Q0UKW4LrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = generate_term_document('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Implementation##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topicmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicmodels.LDA.LDAGibbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 topics\n",
    "ldaobj = topicmodels.LDA.LDAGibbs(text,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of (collapsed) Gibbs sampling\n",
      "Iteration 20 of (collapsed) Gibbs sampling\n",
      "Iteration 30 of (collapsed) Gibbs sampling\n",
      "Iteration 40 of (collapsed) Gibbs sampling\n",
      "Iteration 50 of (collapsed) Gibbs sampling\n",
      "Iteration 60 of (collapsed) Gibbs sampling\n",
      "Iteration 70 of (collapsed) Gibbs sampling\n",
      "Iteration 80 of (collapsed) Gibbs sampling\n",
      "Iteration 90 of (collapsed) Gibbs sampling\n",
      "Iteration 100 of (collapsed) Gibbs sampling\n",
      "Iteration 110 of (collapsed) Gibbs sampling\n",
      "Iteration 120 of (collapsed) Gibbs sampling\n",
      "Iteration 130 of (collapsed) Gibbs sampling\n",
      "Iteration 140 of (collapsed) Gibbs sampling\n",
      "Iteration 150 of (collapsed) Gibbs sampling\n",
      "Iteration 160 of (collapsed) Gibbs sampling\n",
      "Iteration 170 of (collapsed) Gibbs sampling\n",
      "Iteration 180 of (collapsed) Gibbs sampling\n",
      "Iteration 190 of (collapsed) Gibbs sampling\n",
      "Iteration 200 of (collapsed) Gibbs sampling\n",
      "Iteration 210 of (collapsed) Gibbs sampling\n",
      "Iteration 220 of (collapsed) Gibbs sampling\n",
      "Iteration 230 of (collapsed) Gibbs sampling\n",
      "Iteration 240 of (collapsed) Gibbs sampling\n",
      "Iteration 250 of (collapsed) Gibbs sampling\n",
      "Iteration 260 of (collapsed) Gibbs sampling\n",
      "Iteration 270 of (collapsed) Gibbs sampling\n",
      "Iteration 280 of (collapsed) Gibbs sampling\n",
      "Iteration 290 of (collapsed) Gibbs sampling\n",
      "Iteration 300 of (collapsed) Gibbs sampling\n",
      "Iteration 310 of (collapsed) Gibbs sampling\n",
      "Iteration 320 of (collapsed) Gibbs sampling\n",
      "Iteration 330 of (collapsed) Gibbs sampling\n",
      "Iteration 340 of (collapsed) Gibbs sampling\n",
      "Iteration 350 of (collapsed) Gibbs sampling\n",
      "Iteration 360 of (collapsed) Gibbs sampling\n",
      "Iteration 370 of (collapsed) Gibbs sampling\n",
      "Iteration 380 of (collapsed) Gibbs sampling\n",
      "Iteration 390 of (collapsed) Gibbs sampling\n",
      "Iteration 400 of (collapsed) Gibbs sampling\n",
      "Iteration 410 of (collapsed) Gibbs sampling\n",
      "Iteration 420 of (collapsed) Gibbs sampling\n",
      "Iteration 430 of (collapsed) Gibbs sampling\n",
      "Iteration 440 of (collapsed) Gibbs sampling\n",
      "Iteration 450 of (collapsed) Gibbs sampling\n",
      "Iteration 460 of (collapsed) Gibbs sampling\n",
      "Iteration 470 of (collapsed) Gibbs sampling\n",
      "Iteration 480 of (collapsed) Gibbs sampling\n",
      "Iteration 490 of (collapsed) Gibbs sampling\n",
      "Iteration 500 of (collapsed) Gibbs sampling\n",
      "Iteration 510 of (collapsed) Gibbs sampling\n",
      "Iteration 520 of (collapsed) Gibbs sampling\n",
      "Iteration 530 of (collapsed) Gibbs sampling\n",
      "Iteration 540 of (collapsed) Gibbs sampling\n",
      "Iteration 550 of (collapsed) Gibbs sampling\n",
      "Iteration 560 of (collapsed) Gibbs sampling\n",
      "Iteration 570 of (collapsed) Gibbs sampling\n",
      "Iteration 580 of (collapsed) Gibbs sampling\n",
      "Iteration 590 of (collapsed) Gibbs sampling\n",
      "Iteration 600 of (collapsed) Gibbs sampling\n"
     ]
    }
   ],
   "source": [
    "# Gibbs sampling\n",
    "ldaobj.sample(100,50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02358491, 0.02924528, 0.02358491, ..., 0.02358491, 0.02358491,\n",
       "        0.02358491],\n",
       "       [0.02272727, 0.05363636, 0.02272727, ..., 0.02272727, 0.02272727,\n",
       "        0.02636364],\n",
       "       [0.02647059, 0.03235294, 0.0245098 , ..., 0.0245098 , 0.0245098 ,\n",
       "        0.0245098 ],\n",
       "       ...,\n",
       "       [0.0221519 , 0.0943038 , 0.01962025, ..., 0.03607595, 0.01708861,\n",
       "        0.01962025],\n",
       "       [0.02403846, 0.02403846, 0.02403846, ..., 0.02403846, 0.02403846,\n",
       "        0.02403846],\n",
       "       [0.01607143, 0.12559524, 0.01607143, ..., 0.02083333, 0.01488095,\n",
       "        0.01607143]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theta matrix\n",
    "ldaobj.dt_avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.50868051e-07, 8.20897305e-07, 5.23757390e-07, ...,\n",
       "        5.73871215e-07, 4.77690828e-07, 6.60305428e-07],\n",
       "       [1.99252556e-03, 8.20897305e-07, 1.34451101e-02, ...,\n",
       "        5.73871215e-07, 4.77690828e-07, 6.60305428e-07],\n",
       "       [1.31936203e-03, 8.20897305e-07, 2.76601041e-06, ...,\n",
       "        5.73871215e-07, 1.70784621e-03, 3.67407837e-06],\n",
       "       ...,\n",
       "       [1.66711393e-05, 3.49876065e-04, 5.41403683e-06, ...,\n",
       "        5.73871215e-07, 4.77690828e-07, 6.60305428e-07],\n",
       "       [6.51932019e-06, 8.20897305e-07, 5.23757390e-07, ...,\n",
       "        2.91732828e-06, 4.81985323e-06, 1.27852711e-03],\n",
       "       [2.48322314e-06, 8.55993689e-06, 5.23757390e-07, ...,\n",
       "        5.73871215e-07, 8.38732050e-05, 3.67407837e-06]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B matrix\n",
    "ldaobj.tt_avg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF with ANLS\n",
    "\n",
    "using numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "@numba.jit\n",
    "def NMF_ANLS_full(P,k):\n",
    "\n",
    "    B = np.random.uniform(low = 1, high = 1000,size = (P.shape[0], k))\n",
    "    B = B/B.sum(axis = 0)\n",
    "\n",
    "    return B, NMF_ANLS(B,P)\n",
    "\n",
    "@numba.jit\n",
    "def NMF_ANLS(B, P):\n",
    "    \n",
    "    theta = np.zeros(shape = (B.shape[1],P.shape[1]))\n",
    "    \n",
    "    for i,column in enumerate(P.T):\n",
    "        theta[:,i] = ANLS_column(B, column)\n",
    "        \n",
    "    return theta\n",
    "\n",
    "@numba.jit\n",
    "def ANLS_column(B, y):\n",
    "    \n",
    "    m,n = B.shape\n",
    "    g = np.zeros(n)\n",
    "    E = np.arange(n)\n",
    "    S = np.array([])\n",
    "    w = np.matmul(B.T, y-np.matmul(B,g))\n",
    "    \n",
    "\n",
    "    while len(E) != 0 and w[E].max() > 0:\n",
    "        \n",
    "        t = w[E].argmax()\n",
    "        E = np.delete(E, t).astype(int)\n",
    "        S = np.append(S,t).astype(int)\n",
    "        \n",
    "        Bs = B.copy()\n",
    "        Bs[:,E] = 0\n",
    "        \n",
    "        z = np.linalg.lstsq(Bs, y, rcond=None)[0]\n",
    "        z[E] = 0\n",
    "\n",
    "        while z[S].max() <= 0:\n",
    "            \n",
    "            alpha = (g/(g-z))[S].min()\n",
    "            \n",
    "            g = g + alpha*(z-g)\n",
    "            \n",
    "            s_move = S[g[S] == 0]\n",
    "            S = np.delete(S, s_move).astype(int)\n",
    "            E = np.append(E, s_move).astype(int)\n",
    "            Bs = B.copy()\n",
    "            Bs[:,E] = 0            \n",
    "            z = np.linalg.lstsq(Bs, y, rcond=None)[0]\n",
    "            #z[E] = 0\n",
    "        g = z\n",
    "        w = np.matmul(B.T, y-np.matmul(B,g))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_matrix_pd = pd.read_csv('Matrix_interjection_tfidf.csv')\n",
    "td_matrix_pd = td_matrix_pd.replace(0,1e-10)\n",
    "td_matrix = td_matrix_pd.values\n",
    "td_matrix = td_matrix / td_matrix.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "B, theta = NMF_ANLS_full(td_matrix, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19718208e-04, 3.93571793e-05, 1.07589936e-04, ...,\n",
       "        1.05391241e-04, 1.60764049e-04, 1.49846546e-04],\n",
       "       [5.09108670e-05, 5.73868558e-05, 1.64714438e-04, ...,\n",
       "        1.66758255e-04, 1.51094051e-04, 1.32195319e-04],\n",
       "       [9.97753619e-05, 3.79426938e-05, 1.54162546e-04, ...,\n",
       "        1.63566411e-04, 7.51839910e-05, 2.02922270e-04],\n",
       "       ...,\n",
       "       [3.89136061e-05, 1.10068356e-04, 3.79175898e-05, ...,\n",
       "        4.79770315e-05, 3.20093167e-05, 1.81468919e-05],\n",
       "       [1.09339532e-04, 9.88638699e-06, 1.49133855e-04, ...,\n",
       "        7.30981828e-05, 4.97122240e-06, 4.31877120e-05],\n",
       "       [4.70511656e-05, 8.90459788e-05, 6.47713425e-05, ...,\n",
       "        1.66646211e-04, 5.70052184e-05, 1.13227763e-04]])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01700569, 0.        , 0.06449576, ..., 0.        , 0.        ,\n",
       "        0.36436682],\n",
       "       [0.02302282, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02848518, 0.        , 0.        , ..., 0.04541429, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.01864526, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.03785548],\n",
       "       [0.02085815, 0.        , 0.96290561, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02565627, 0.30553623, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
